diff --git a/solr/core/src/java/org/apache/solr/update/processor/CdcrUpdateProcessor.java b/solr/core/src/java/org/apache/solr/update/processor/CdcrUpdateProcessor.java
index ee45467076..6b23a73980 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/CdcrUpdateProcessor.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/CdcrUpdateProcessor.java
@@ -32,9 +32,7 @@ import org.slf4j.LoggerFactory;
 
 /**
  * <p>
- * Extends {@link org.apache.solr.update.processor.DistributedUpdateProcessor} to force peer sync logic
- * for every updates. This ensures that the version parameter sent by the source cluster is kept
- * by the target cluster.
+ * Extends {@link org.apache.solr.update.processor.DistributedUpdateProcessor}
  * </p>
  */
 public class CdcrUpdateProcessor extends DistributedUpdateProcessor {
@@ -49,47 +47,13 @@ public class CdcrUpdateProcessor extends DistributedUpdateProcessor {
 
   @Override
   protected boolean versionAdd(AddUpdateCommand cmd) throws IOException {
-    /*
-    temporarily set the PEER_SYNC flag so that DistributedUpdateProcessor.versionAdd doesn't execute leader logic
-    but the else part of that if. That way version remains preserved.
-
-    we cannot set the flag for the whole processAdd method because DistributedUpdateProcessor.setupRequest() would set
-    isLeader to false which wouldn't work
-     */
-    if (cmd.getReq().getParams().get(CDCR_UPDATE) != null) {
-      cmd.setFlags(cmd.getFlags() | UpdateCommand.PEER_SYNC); // we need super.versionAdd() to set leaderLogic to false
-    }
-
     boolean result = super.versionAdd(cmd);
-
-    // unset the flag to avoid unintended consequences down the chain
-    if (cmd.getReq().getParams().get(CDCR_UPDATE) != null) {
-      cmd.setFlags(cmd.getFlags() & ~UpdateCommand.PEER_SYNC);
-    }
-
     return result;
   }
 
   @Override
   protected boolean versionDelete(DeleteUpdateCommand cmd) throws IOException {
-    /*
-    temporarily set the PEER_SYNC flag so that DistributedUpdateProcessor.deleteAdd doesn't execute leader logic
-    but the else part of that if. That way version remains preserved.
-
-    we cannot set the flag for the whole processDelete method because DistributedUpdateProcessor.setupRequest() would set
-    isLeader to false which wouldn't work
-     */
-    if (cmd.getReq().getParams().get(CDCR_UPDATE) != null) {
-      cmd.setFlags(cmd.getFlags() | UpdateCommand.PEER_SYNC); // we need super.versionAdd() to set leaderLogic to false
-    }
-
     boolean result = super.versionDelete(cmd);
-
-    // unset the flag to avoid unintended consequences down the chain
-    if (cmd.getReq().getParams().get(CDCR_UPDATE) != null) {
-      cmd.setFlags(cmd.getFlags() & ~UpdateCommand.PEER_SYNC);
-    }
-
     return result;
   }
 
@@ -110,21 +74,7 @@ public class CdcrUpdateProcessor extends DistributedUpdateProcessor {
 
   @Override
   protected void versionDeleteByQuery(DeleteUpdateCommand cmd) throws IOException {
-    /*
-    temporarily set the PEER_SYNC flag so that DistributedUpdateProcessor.versionDeleteByQuery doesn't execute leader logic
-    That way version remains preserved.
-
-     */
-    if (cmd.getReq().getParams().get(CDCR_UPDATE) != null) {
-      cmd.setFlags(cmd.getFlags() | UpdateCommand.PEER_SYNC); // we need super.versionDeleteByQuery() to set leaderLogic to false
-    }
-
     super.versionDeleteByQuery(cmd);
-
-    // unset the flag to avoid unintended consequences down the chain
-    if (cmd.getReq().getParams().get(CDCR_UPDATE) != null) {
-      cmd.setFlags(cmd.getFlags() & ~UpdateCommand.PEER_SYNC);
-    }
   }
 }
 
diff --git a/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java b/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java
index d5e4194b15..7a8fc8d940 100644
--- a/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java
+++ b/solr/core/src/java/org/apache/solr/update/processor/DistributedUpdateProcessor.java
@@ -1036,7 +1036,7 @@ public class DistributedUpdateProcessor extends UpdateRequestProcessor {
 
           long bucketVersion = bucket.highest;
 
-          if (leaderLogic) {
+          if (leaderLogic && !isCdcrConfigured(cmd)) {
 
             if (forwardedFromCollection && ulog.getState() == UpdateLog.State.ACTIVE) {
               // forwarded from a collection but we are not buffering so strip original version and apply our own
@@ -1146,7 +1146,8 @@ public class DistributedUpdateProcessor extends UpdateRequestProcessor {
                 }
               }
             }
-            if (replicaType == Replica.Type.TLOG && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {
+            if (replicaType == Replica.Type.TLOG && (cmd.getFlags() & UpdateCommand.REPLAY) == 0 &&
+                !isCdcrConfiguredAndLeader(cmd)) {
               cmd.setFlags(cmd.getFlags() | UpdateCommand.IGNORE_INDEXWRITER);
             }
           }
@@ -1602,7 +1603,7 @@ public class DistributedUpdateProcessor extends UpdateRequestProcessor {
         Thread.currentThread().interrupt();
         throw new ZooKeeperException(ErrorCode.SERVER_ERROR, "", e);
       }
-      if (leaderLogic) {
+      if (leaderLogic && !isCdcrConfigured(cmd)) {
         List<Node> subShardLeaders = getSubShardLeaders(coll, cloudDesc.getShardId(), null, null);
         if (subShardLeaders != null)  {
           cmdDistrib.distribDelete(cmd, subShardLeaders, params, true, rollupReplicationTracker, leaderReplicationTracker);
@@ -1676,7 +1677,8 @@ public class DistributedUpdateProcessor extends UpdateRequestProcessor {
             return;
           }
 
-          if (replicaType == Replica.Type.TLOG && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {
+          if (replicaType == Replica.Type.TLOG && (cmd.getFlags() & UpdateCommand.REPLAY) == 0 &&
+              !isCdcrConfiguredAndLeader(cmd)) {
             // TLOG replica not leader, don't write the DBQ to IW
             cmd.setFlags(cmd.getFlags() | UpdateCommand.IGNORE_INDEXWRITER);
           }
@@ -1714,6 +1716,16 @@ public class DistributedUpdateProcessor extends UpdateRequestProcessor {
     return isLeader;
   }
 
+  //internal helper method to determine if cdcr is also configured
+  boolean isCdcrConfigured(UpdateCommand cmd) {
+    return (cmd.getReq().getParams().get(CdcrUpdateProcessor.CDCR_UPDATE) != null);
+  }
+
+  //internal helper method to determine if we are leader and cdcr is also configured
+  boolean isCdcrConfiguredAndLeader(UpdateCommand cmd) {
+    return (isLeader && isCdcrConfigured(cmd));
+  }
+
   private void zkCheck() {
 
     // Streaming updates can delay shutdown and cause big update reorderings (new streams can't be
@@ -1776,7 +1788,7 @@ public class DistributedUpdateProcessor extends UpdateRequestProcessor {
         if (versionsStored) {
           long bucketVersion = bucket.highest;
 
-          if (leaderLogic) {
+          if (leaderLogic && !isCdcrConfigured(cmd)) {
 
             if (forwardedFromCollection && ulog.getState() == UpdateLog.State.ACTIVE) {
               // forwarded from a collection but we are not buffering so strip original version and apply our own
@@ -1835,7 +1847,8 @@ public class DistributedUpdateProcessor extends UpdateRequestProcessor {
               }
             }
 
-            if (replicaType == Replica.Type.TLOG && (cmd.getFlags() & UpdateCommand.REPLAY) == 0) {
+            if (replicaType == Replica.Type.TLOG && (cmd.getFlags() & UpdateCommand.REPLAY) == 0 &&
+                !isCdcrConfiguredAndLeader(cmd)) {
               cmd.setFlags(cmd.getFlags() | UpdateCommand.IGNORE_INDEXWRITER);
             }
           }
diff --git a/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrWithDiffReplicaTypes.java b/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrWithDiffReplicaTypes.java
new file mode 100644
index 0000000000..01e6dc2fe8
--- /dev/null
+++ b/solr/core/src/test/org/apache/solr/cloud/cdcr/CdcrWithDiffReplicaTypes.java
@@ -0,0 +1,353 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.solr.cloud.cdcr;
+
+import java.lang.invoke.MethodHandles;
+import java.util.concurrent.TimeUnit;
+
+import com.google.common.collect.ImmutableMap;
+import org.apache.solr.SolrTestCaseJ4;
+import org.apache.solr.client.solrj.SolrQuery;
+import org.apache.solr.client.solrj.impl.CloudSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.CollectionAdminRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.client.solrj.response.QueryResponse;
+import org.apache.solr.cloud.MiniSolrCloudCluster;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.handler.CdcrParams;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class CdcrWithDiffReplicaTypes extends SolrTestCaseJ4 {
+
+  private static final Logger log = LoggerFactory.getLogger(MethodHandles.lookup().lookupClass());
+
+  @Test
+  public void testTlogReplica() throws Exception {
+    MiniSolrCloudCluster cluster2 = new MiniSolrCloudCluster(1, createTempDir("cdcr-cluster2"), buildJettyConfig("/solr"));
+    cluster2.waitForAllNodes(30);
+    MiniSolrCloudCluster cluster1 = new MiniSolrCloudCluster(1, createTempDir("cdcr-cluster1"), buildJettyConfig("/solr"));
+    cluster1.waitForAllNodes(30);
+    try {
+      log.info("cluster2 zkHost = " + cluster2.getZkServer().getZkAddress());
+      System.setProperty("cdcr.cluster2.zkHost", cluster2.getZkServer().getZkAddress());
+
+      log.info("cluster1 zkHost = " + cluster1.getZkServer().getZkAddress());
+      System.setProperty("cdcr.cluster1.zkHost", cluster1.getZkServer().getZkAddress());
+
+
+      cluster1.uploadConfigSet(configset("cdcr-cluster1"), "cdcr-cluster1");
+      CollectionAdminRequest.createCollection("cdcr-cluster1", "cdcr-cluster1", 1, 0, 2, 0)
+          .withProperty("solr.directoryFactory", "solr.StandardDirectoryFactory")
+          .setMaxShardsPerNode(2)
+          .process(cluster1.getSolrClient());
+      CloudSolrClient cluster1SolrClient = cluster1.getSolrClient();
+      cluster1SolrClient.setDefaultCollection("cdcr-cluster1");
+
+      cluster2.uploadConfigSet(configset("cdcr-cluster2"), "cdcr-cluster2");
+      CollectionAdminRequest.createCollection("cdcr-cluster2", "cdcr-cluster2", 1, 0, 2, 0)
+          .withProperty("solr.directoryFactory", "solr.StandardDirectoryFactory")
+          .setMaxShardsPerNode(2)
+          .process(cluster2.getSolrClient());
+      CloudSolrClient cluster2SolrClient = cluster2.getSolrClient();
+      cluster2SolrClient.setDefaultCollection("cdcr-cluster2");
+
+      UpdateRequest req = null;
+
+      CdcrTestsUtil.cdcrStart(cluster1SolrClient);
+      Thread.sleep(2000);
+
+      // ADD operation on cluster 1
+      int docs = (TEST_NIGHTLY ? 100 : 10);
+      int numDocs_c1 = 0;
+      for (int k = 0; k < docs; k++) {
+        req = new UpdateRequest();
+        for (; numDocs_c1 < (k + 1) * 100; numDocs_c1++) {
+          SolrInputDocument doc = new SolrInputDocument();
+          doc.addField("id", "cluster1_" + numDocs_c1);
+          doc.addField("xyz", numDocs_c1);
+          req.add(doc);
+        }
+        req.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);
+        log.info("Adding " + docs + " docs with commit=true, numDocs=" + numDocs_c1);
+        req.process(cluster1SolrClient);
+      }
+
+      QueryResponse response = cluster1SolrClient.query(new SolrQuery("*:*"));
+      assertEquals("cluster 1 docs mismatch", numDocs_c1, response.getResults().getNumFound());
+
+      assertEquals("cluster 2 docs mismatch", numDocs_c1, CdcrTestsUtil.waitForClusterToSync(numDocs_c1, cluster2SolrClient));
+
+      CdcrTestsUtil.cdcrStart(cluster2SolrClient); // FULL BI-DIRECTIONAL CDCR FORWARDING ON
+      Thread.sleep(2000);
+
+      // ADD operation on cluster 2
+      int numDocs_c2 = 0;
+      for (int k = 0; k < docs; k++) {
+        req = new UpdateRequest();
+        for (; numDocs_c2 < (k + 1) * 100; numDocs_c2++) {
+          SolrInputDocument doc = new SolrInputDocument();
+          doc.addField("id", "cluster2_" + numDocs_c2);
+          doc.addField("xyz", numDocs_c2);
+          req.add(doc);
+        }
+        req.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);
+        log.info("Adding " + docs + " docs with commit=true, numDocs=" + numDocs_c2);
+        req.process(cluster2SolrClient);
+      }
+
+      int numDocs = numDocs_c1 + numDocs_c2;
+
+      response = cluster2SolrClient.query(new SolrQuery("*:*"));
+      assertEquals("cluster 2 docs mismatch", numDocs, response.getResults().getNumFound());
+
+      assertEquals("cluster 1 docs mismatch", numDocs, CdcrTestsUtil.waitForClusterToSync(numDocs, cluster1SolrClient));
+
+      // logging cdcr clusters queue response
+      response = CdcrTestsUtil.getCdcrQueue(cluster1SolrClient);
+      log.info("Cdcr cluster1 queue response: " + response.getResponse());
+      response = CdcrTestsUtil.getCdcrQueue(cluster2SolrClient);
+      log.info("Cdcr cluster2 queue response: " + response.getResponse());
+
+
+      // DELETE BY QUERY
+      String deleteByQuery = "id:cluster1_" +String.valueOf(random().nextInt(numDocs_c1));
+      response = cluster1SolrClient.query(new SolrQuery(deleteByQuery));
+      assertEquals("should match exactly one doc", 1, response.getResults().getNumFound());
+      cluster1SolrClient.deleteByQuery(deleteByQuery);
+      cluster1SolrClient.commit();
+      numDocs--;
+      numDocs_c1--;
+
+      response = cluster1SolrClient.query(new SolrQuery("*:*"));
+      assertEquals("cluster 1 docs mismatch", numDocs, response.getResults().getNumFound());
+      assertEquals("cluster 2 docs mismatch", numDocs, CdcrTestsUtil.waitForClusterToSync(numDocs, cluster2SolrClient));
+
+      // DELETE BY ID
+      SolrInputDocument doc;
+      String delete_id_query = "cluster2_" + random().nextInt(numDocs_c2);
+      cluster2SolrClient.deleteById(delete_id_query);
+      cluster2SolrClient.commit();
+      numDocs--;
+      numDocs_c2--;
+      response = cluster2SolrClient.query(new SolrQuery("*:*"));
+      assertEquals("cluster 2 docs mismatch", numDocs, response.getResults().getNumFound());
+      assertEquals("cluster 1 docs mismatch", numDocs, CdcrTestsUtil.waitForClusterToSync(numDocs, cluster1SolrClient));
+
+      // ATOMIC UPDATES
+      req = new UpdateRequest();
+      doc = new SolrInputDocument();
+      ImmutableMap.of("", "");
+      String atomicUpdateId = "cluster2_" + random().nextInt(numDocs_c2);
+      doc.addField("id", atomicUpdateId);
+      doc.addField("xyz", ImmutableMap.of("delete", ""));
+      doc.addField("abc", ImmutableMap.of("set", "ABC"));
+      req.add(doc);
+      req.process(cluster2SolrClient);
+      cluster2SolrClient.commit();
+
+      String atomicQuery = "id:" + atomicUpdateId;
+      response = cluster2SolrClient.query(new SolrQuery(atomicQuery));
+      assertEquals("cluster 2 wrong doc", "ABC", response.getResults().get(0).get("abc"));
+      assertEquals("cluster 1 wrong doc", "ABC", getDocFieldValue(cluster1SolrClient, atomicQuery, "ABC"));
+
+
+      // logging cdcr clusters queue response
+      response = CdcrTestsUtil.getCdcrQueue(cluster1SolrClient);
+      log.info("Cdcr cluster1 queue response at end of testcase: " + response.getResponse());
+      response = CdcrTestsUtil.getCdcrQueue(cluster2SolrClient);
+      log.info("Cdcr cluster2 queue response at end of testcase: " + response.getResponse());
+
+      CdcrTestsUtil.cdcrStop(cluster1SolrClient);
+      CdcrTestsUtil.cdcrStop(cluster2SolrClient);
+    } finally {
+      if (cluster1 != null) {
+        cluster1.shutdown();
+      }
+      if (cluster2 != null) {
+        cluster2.shutdown();
+      }
+    }
+  }
+
+  @Test
+  public void testNRTAndTlogReplica() throws Exception {
+    MiniSolrCloudCluster cluster2 = new MiniSolrCloudCluster(1, createTempDir("cdcr-cluster2"), buildJettyConfig("/solr"));
+    cluster2.waitForAllNodes(30);
+    MiniSolrCloudCluster cluster1 = new MiniSolrCloudCluster(1, createTempDir("cdcr-cluster1"), buildJettyConfig("/solr"));
+    cluster1.waitForAllNodes(30);
+    try {
+      log.info("cluster2 zkHost = " + cluster2.getZkServer().getZkAddress());
+      System.setProperty("cdcr.cluster2.zkHost", cluster2.getZkServer().getZkAddress());
+
+      log.info("cluster1 zkHost = " + cluster1.getZkServer().getZkAddress());
+      System.setProperty("cdcr.cluster1.zkHost", cluster1.getZkServer().getZkAddress());
+
+
+      cluster1.uploadConfigSet(configset("cdcr-cluster1"), "cdcr-cluster1");
+      CollectionAdminRequest.createCollection("cdcr-cluster1", "cdcr-cluster1", 1, 1, 1, 0)
+          .withProperty("solr.directoryFactory", "solr.StandardDirectoryFactory")
+          .setMaxShardsPerNode(2)
+          .process(cluster1.getSolrClient());
+      CloudSolrClient cluster1SolrClient = cluster1.getSolrClient();
+      cluster1SolrClient.setDefaultCollection("cdcr-cluster1");
+
+      cluster2.uploadConfigSet(configset("cdcr-cluster2"), "cdcr-cluster2");
+      CollectionAdminRequest.createCollection("cdcr-cluster2", "cdcr-cluster2", 1, 1, 1, 0)
+          .withProperty("solr.directoryFactory", "solr.StandardDirectoryFactory")
+          .setMaxShardsPerNode(2)
+          .process(cluster2.getSolrClient());
+      CloudSolrClient cluster2SolrClient = cluster2.getSolrClient();
+      cluster2SolrClient.setDefaultCollection("cdcr-cluster2");
+
+      UpdateRequest req = null;
+
+      CdcrTestsUtil.cdcrStart(cluster1SolrClient);
+      Thread.sleep(2000);
+
+      // ADD operation on cluster 1
+      int docs = (TEST_NIGHTLY ? 100 : 10);
+      int numDocs_c1 = 0;
+      for (int k = 0; k < docs; k++) {
+        req = new UpdateRequest();
+        for (; numDocs_c1 < (k + 1) * 100; numDocs_c1++) {
+          SolrInputDocument doc = new SolrInputDocument();
+          doc.addField("id", "cluster1_" + numDocs_c1);
+          doc.addField("xyz", numDocs_c1);
+          req.add(doc);
+        }
+        req.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);
+        log.info("Adding " + docs + " docs with commit=true, numDocs=" + numDocs_c1);
+        req.process(cluster1SolrClient);
+      }
+
+      QueryResponse response = cluster1SolrClient.query(new SolrQuery("*:*"));
+      assertEquals("cluster 1 docs mismatch", numDocs_c1, response.getResults().getNumFound());
+
+      assertEquals("cluster 2 docs mismatch", numDocs_c1, CdcrTestsUtil.waitForClusterToSync(numDocs_c1, cluster2SolrClient));
+
+      CdcrTestsUtil.cdcrStart(cluster2SolrClient); // FULL BI-DIRECTIONAL CDCR FORWARDING ON
+      Thread.sleep(2000);
+
+      // ADD operation on cluster 2
+      int numDocs_c2 = 0;
+      for (int k = 0; k < docs; k++) {
+        req = new UpdateRequest();
+        for (; numDocs_c2 < (k + 1) * 100; numDocs_c2++) {
+          SolrInputDocument doc = new SolrInputDocument();
+          doc.addField("id", "cluster2_" + numDocs_c2);
+          doc.addField("xyz", numDocs_c2);
+          req.add(doc);
+        }
+        req.setAction(AbstractUpdateRequest.ACTION.COMMIT, true, true);
+        log.info("Adding " + docs + " docs with commit=true, numDocs=" + numDocs_c2);
+        req.process(cluster2SolrClient);
+      }
+
+      int numDocs = numDocs_c1 + numDocs_c2;
+
+      response = cluster2SolrClient.query(new SolrQuery("*:*"));
+      assertEquals("cluster 2 docs mismatch", numDocs, response.getResults().getNumFound());
+
+      assertEquals("cluster 1 docs mismatch", numDocs, CdcrTestsUtil.waitForClusterToSync(numDocs, cluster1SolrClient));
+
+      // logging cdcr clusters queue response
+      response = CdcrTestsUtil.getCdcrQueue(cluster1SolrClient);
+      log.info("Cdcr cluster1 queue response: " + response.getResponse());
+      response = CdcrTestsUtil.getCdcrQueue(cluster2SolrClient);
+      log.info("Cdcr cluster2 queue response: " + response.getResponse());
+
+
+      // DELETE BY QUERY
+      String deleteByQuery = "id:cluster1_" +String.valueOf(random().nextInt(numDocs_c1));
+      response = cluster1SolrClient.query(new SolrQuery(deleteByQuery));
+      assertEquals("should match exactly one doc", 1, response.getResults().getNumFound());
+      cluster1SolrClient.deleteByQuery(deleteByQuery);
+      cluster1SolrClient.commit();
+      numDocs--;
+      numDocs_c1--;
+
+      response = cluster1SolrClient.query(new SolrQuery("*:*"));
+      assertEquals("cluster 1 docs mismatch", numDocs, response.getResults().getNumFound());
+      assertEquals("cluster 2 docs mismatch", numDocs, CdcrTestsUtil.waitForClusterToSync(numDocs, cluster2SolrClient));
+
+      // DELETE BY ID
+      SolrInputDocument doc;
+      String delete_id_query = "cluster2_" + random().nextInt(numDocs_c2);
+      cluster2SolrClient.deleteById(delete_id_query);
+      cluster2SolrClient.commit();
+      numDocs--;
+      numDocs_c2--;
+      response = cluster2SolrClient.query(new SolrQuery("*:*"));
+      assertEquals("cluster 2 docs mismatch", numDocs, response.getResults().getNumFound());
+      assertEquals("cluster 1 docs mismatch", numDocs, CdcrTestsUtil.waitForClusterToSync(numDocs, cluster1SolrClient));
+
+      // ATOMIC UPDATES
+      req = new UpdateRequest();
+      doc = new SolrInputDocument();
+      ImmutableMap.of("", "");
+      String atomicUpdateId = "cluster2_" + random().nextInt(numDocs_c2);
+      doc.addField("id", atomicUpdateId);
+      doc.addField("xyz", ImmutableMap.of("delete", ""));
+      doc.addField("abc", ImmutableMap.of("set", "ABC"));
+      req.add(doc);
+      req.process(cluster2SolrClient);
+      cluster2SolrClient.commit();
+
+      String atomicQuery = "id:" + atomicUpdateId;
+      response = cluster2SolrClient.query(new SolrQuery(atomicQuery));
+      assertEquals("cluster 2 wrong doc", "ABC", response.getResults().get(0).get("abc"));
+      assertEquals("cluster 1 wrong doc", "ABC", getDocFieldValue(cluster1SolrClient, atomicQuery, "ABC"));
+
+
+      // logging cdcr clusters queue response
+      response = CdcrTestsUtil.getCdcrQueue(cluster1SolrClient);
+      log.info("Cdcr cluster1 queue response at end of testcase: " + response.getResponse());
+      response = CdcrTestsUtil.getCdcrQueue(cluster2SolrClient);
+      log.info("Cdcr cluster2 queue response at end of testcase: " + response.getResponse());
+
+      CdcrTestsUtil.cdcrStop(cluster1SolrClient);
+      CdcrTestsUtil.cdcrStop(cluster2SolrClient);
+    } finally {
+      if (cluster1 != null) {
+        cluster1.shutdown();
+      }
+      if (cluster2 != null) {
+        cluster2.shutdown();
+      }
+    }
+  }
+
+  private String getDocFieldValue(CloudSolrClient clusterSolrClient, String query, String match) throws Exception {
+    long start = System.nanoTime();
+    QueryResponse response = null;
+    while (System.nanoTime() - start <= TimeUnit.NANOSECONDS.convert(120, TimeUnit.SECONDS)) {
+      clusterSolrClient.commit();
+      response = clusterSolrClient.query(new SolrQuery(query));
+      if (match.equals(response.getResults().get(0).get("abc"))) {
+        break;
+      }
+      Thread.sleep(1000);
+    }
+    return response != null ? (String) response.getResults().get(0).get("abc") : "";
+  }
+}
